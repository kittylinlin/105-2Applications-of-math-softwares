{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 利用LSTM訓練神經網路寫文章    \n",
    "[參考網站]( https://github.com/fchollet/keras/blob/master/examples/lstm_text_generation.py)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 引入套件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.layers import LSTM\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.utils.data_utils import get_file\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 讀入訓練資料    \n",
    "我想作者是使用[這個網站](https://aws.amazon.com/tw/s3/)將尼采的文章做成純文字檔，再讀入Python。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/text-datasets/nietzsche.txt\n"
     ]
    }
   ],
   "source": [
    "path = get_file('nietzsche.txt', origin='https://s3.amazonaws.com/text-datasets/nietzsche.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text = open(path, encoding=\"utf-8\").read().lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "全集字數: 600893\n"
     ]
    }
   ],
   "source": [
    "print('全集字數:', len(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 整理訓練資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "特殊字元符號數: 57\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "print('特殊字元符號數:', len(chars))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "看一下```chars```的長相："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\n',\n",
       " ' ',\n",
       " '!',\n",
       " '\"',\n",
       " \"'\",\n",
       " '(',\n",
       " ')',\n",
       " ',',\n",
       " '-',\n",
       " '.',\n",
       " '0',\n",
       " '1',\n",
       " '2',\n",
       " '3',\n",
       " '4',\n",
       " '5',\n",
       " '6',\n",
       " '7',\n",
       " '8',\n",
       " '9',\n",
       " ':',\n",
       " ';',\n",
       " '=',\n",
       " '?',\n",
       " '[',\n",
       " ']',\n",
       " '_',\n",
       " 'a',\n",
       " 'b',\n",
       " 'c',\n",
       " 'd',\n",
       " 'e',\n",
       " 'f',\n",
       " 'g',\n",
       " 'h',\n",
       " 'i',\n",
       " 'j',\n",
       " 'k',\n",
       " 'l',\n",
       " 'm',\n",
       " 'n',\n",
       " 'o',\n",
       " 'p',\n",
       " 'q',\n",
       " 'r',\n",
       " 's',\n",
       " 't',\n",
       " 'u',\n",
       " 'v',\n",
       " 'w',\n",
       " 'x',\n",
       " 'y',\n",
       " 'z',\n",
       " 'ä',\n",
       " 'æ',\n",
       " 'é',\n",
       " 'ë']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "將```chars```裡的特殊字元符號用兩種方式編號"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "切割資料方便訓練"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "maxlen = 40\n",
    "step = 3\n",
    "sentences = []\n",
    "next_chars = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb sequences: 200285\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, len(text) - maxlen, step):\n",
    "    sentences.append(text[i: i + maxlen])\n",
    "    next_chars.append(text[i + maxlen])\n",
    "print('nb sequences:', len(sentences))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "將資料向量化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        X[i, t, char_indices[char]] = 1\n",
    "    y[i, char_indices[next_chars[i]]] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 搭建訓練用的神經網路"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.add(LSTM(128, input_shape=(maxlen, len(chars))))\n",
    "model.add(Dense(len(chars)))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(lr=0.01))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "先定義一個輔助函數，處理我們神經網路輸出的機率值："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sample(preds, temperature=1.0):\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "至少需要訓練20次才能讓神經網路寫的文章看起來真的有那麼一回事。    \n",
    "所以原本應該是長這樣...總共要訓練60次，每次都逼神經網路修出自己撰寫文章。    \n",
    "```for 次數 in range(1, 60):     \n",
    "    print('訓練次數: ', 次數)    \n",
    "    model.fit(X, y, batch_size=128, epochs=1)```  \n",
    "    \n",
    "    start_index = np.random.randint(0, len(text) - maxlen - 1)    \n",
    "    \n",
    "    for 多樣性 in [0.2, 0.5, 1.0, 1.2]:    \n",
    "        print()    \n",
    "        print('多樣性: ', 多樣性)    \n",
    "    \n",
    "        generated = ''    \n",
    "        sentence = text[start_index: start_index + maxlen]    \n",
    "        generated += sentence    \n",
    "        print('以此段文字為輸入生成文章: \"' + sentence + '\"')    \n",
    "        sys.stdout.write(generated)    \n",
    "    \n",
    "        for i in range(400):    \n",
    "            x = np.zeros((1, maxlen, len(chars)))    \n",
    "            for t, char in enumerate(sentence):    \n",
    "                x[0, t, char_indices[char]] = 1.    \n",
    "    \n",
    "            preds = model.predict(x, verbose=0)[0]    \n",
    "            next_index = sample(preds, 多樣性)    \n",
    "            next_char = indices_char[next_index]    \n",
    "    \n",
    "            generated += next_char    \n",
    "            sentence = sentence[1:] + next_char     \n",
    "    \n",
    "            sys.stdout.write(next_char)    \n",
    "            sys.stdout.flush()    \n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "但這樣我們就會回不了家，所以先做一次就玩玩看就好了。    \n",
    "* 先訓練"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "200285/200285 [==============================] - 438s - loss: 1.6460   \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x12d0a14e0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y, batch_size=128, epochs=1, verbose=1) #因為是網頁版所以將verbose=0(預設是1)，避免網頁逾時跑不動。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 再生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "多樣性:  0.2\n",
      "以此段文字為輸入生成文章: \"nd so\n",
      "self-disrespectful, and on the oth\"\n",
      "nd so\n",
      "self-disrespectful, and on the other the man in the sensible the in the sense of the some problem of the problem of the sensible to a sense of the sense of the considerable the sense of the problem in the morals of the self--it is all the sense of the sensible the morals and the some procress of the action of the sense of the sense of the consider and the morals and the sense of the in the say to the sensible the procress of the s\n",
      "\n",
      "多樣性:  0.5\n",
      "以此段文字為輸入生成文章: \"es--they will\n",
      "be the men of the future, \"\n",
      "es--they will\n",
      "be the men of the future, and it is the propener to be so good perhaps and intention of the wear and also in the stand and art the problem, to the the discoverman like has all the possible to seever, so the promptent of the desire to in the prict for the head for the say to the sensible in the toodoring least and in the sensible something in the precisely the self--in the deciections of the religion and as a been a littrat\n",
      "\n",
      "多樣性:  1.0\n",
      "以此段文字為輸入生成文章: \"inks: the capable man in the grand style\"\n",
      "inks: the capable man in the grand stylepradrows of nowever to chare the ocestity asageour has indidnance\n",
      "he in such precisely hitherto even the some they,\" at that anny, sensible vire enomost even the tastoousm of much all, or stake, culles even seens aidiona-ind mich\n",
      "enayd to the right and though disolagion of adpies tooser lout its\n",
      "pached, natoie, the becomes intelunge of the the a saceful a at even to an errorned\n",
      "thighs\n",
      "mesure is ma\n",
      "\n",
      "多樣性:  1.2\n",
      "以此段文字為輸入生成文章: \" even if all mankind be taken into consi\"\n",
      " even if all mankind be taken into consight, the sothing main that a (the he. he owintik actly pririoush guilngerisond always,\"--it is al.gar enomenast itself!- \n",
      "prayedly among--    his ooveraman wosce mensicanced speak if higher of imporirating,\n",
      ".venpocaly--and dimsensiving art\n",
      "a dalenty, but itbee, aduny,\n",
      "or adfed has is a light of somets unsivied in fundompatoly, in grown the we is, and jees not unevings goiace upine--which\n",
      "ma\"sfus, \n"
     ]
    }
   ],
   "source": [
    "for 多樣性 in [0.2, 0.5, 1.0, 1.2]:    \n",
    "        print()    \n",
    "        print('多樣性: ', 多樣性)    \n",
    "        \n",
    "        start_index = np.random.randint(0, len(text) - maxlen - 1)\n",
    "        generated = ''    \n",
    "        sentence = text[start_index: start_index + maxlen]    \n",
    "        generated += sentence    \n",
    "        print('以此段文字為輸入生成文章: \"' + sentence + '\"')    \n",
    "        sys.stdout.write(generated)    \n",
    "    \n",
    "        for i in range(400):    \n",
    "            x = np.zeros((1, maxlen, len(chars)))    \n",
    "            for t, char in enumerate(sentence):    \n",
    "                x[0, t, char_indices[char]] = 1.    \n",
    "    \n",
    "            preds = model.predict(x, verbose=0)[0]    \n",
    "            next_index = sample(preds, 多樣性)    \n",
    "            next_char = indices_char[next_index]    \n",
    "    \n",
    "            generated += next_char    \n",
    "            sentence = sentence[1:] + next_char     \n",
    "    \n",
    "            sys.stdout.write(next_char)    \n",
    "            sys.stdout.flush()    \n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
